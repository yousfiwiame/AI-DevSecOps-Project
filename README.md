# AI-DevSecOps Project: Automated Security Policy Generation

A Flask e-commerce application integrated with a complete DevSecOps pipeline that uses Large Language Models (LLMs) to automatically generate security policies from vulnerability reports. This project demonstrates the integration of SAST, SCA, and DAST security tools with AI-assisted policy generation conforming to NIST CSF and ISO/IEC 27001 standards.

## ğŸ“‹ Table of Contents

- [Project Overview](#project-overview)
- [Project Structure](#project-structure)
- [File Documentation](#file-documentation)
- [Getting Started](#getting-started)
- [DevSecOps Pipeline](#devsecops-pipeline)
- [Configuration](#configuration)
- [Evaluation Metrics](#evaluation-metrics)

## ğŸ¯ Project Overview

This project implements a proof-of-concept DevSecOps pipeline that:

1. **Scans for vulnerabilities** using SAST (Static Application Security Testing), SCA (Software Composition Analysis), and DAST (Dynamic Application Security Testing) tools
2. **Parses and normalizes** security reports into a unified format
3. **Generates security policies** using LLMs (OpenAI GPT and Hugging Face models) based on detected vulnerabilities
4. **Evaluates policy quality** using BLEU and ROUGE-L metrics

The Flask application intentionally contains **25+ security vulnerabilities** for testing and demonstration purposes.

## ğŸ“ Project Structure

```
AI-DevSecOps-Project-2/
â”œâ”€â”€ app.py                          # Flask e-commerce application with intentional vulnerabilities
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ README.md                       # This file - comprehensive project documentation
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/                  # GitHub Actions CI/CD workflows
â”‚       â””â”€â”€ devsecops.yml          # Unified DevSecOps pipeline (SAST, SCA, DAST, LLM generation)
â”‚
â”œâ”€â”€ parsers/                        # Vulnerability report parsers
â”‚   â”œâ”€â”€ __init__.py               # Python package initialization
â”‚   â”œâ”€â”€ base_parser.py            # Base parser class with normalization utilities
â”‚   â”œâ”€â”€ sast_parser.py            # SAST report parser (SonarQube, can also handle Bandit)
â”‚   â”œâ”€â”€ sca_parser.py             # SCA report parser (Dependency-Check, pip-audit, Safety)
â”‚   â””â”€â”€ dast_parser.py             # DAST report parser (OWASP ZAP)
â”‚
â”œâ”€â”€ scripts/                        # Utility scripts
â”‚   â”œâ”€â”€ parse_reports.py          # Main script to unify all security reports
â”‚   â”œâ”€â”€ validate_unified_report.py # Validates unified report against schema
â”‚   â”œâ”€â”€ generate_sca_summary.py   # Generates SCA summary from multiple tools
â”‚   â”œâ”€â”€ generate_sast_summary.py  # Generates SAST summary from SonarQube (and optionally Bandit)
â”‚   â””â”€â”€ generate_dast_summary.py  # Generates DAST summary from OWASP ZAP
â”‚
â”œâ”€â”€ schemas/                        # JSON schemas
â”‚   â””â”€â”€ unified_vulnerabilities.schema.json  # Schema for unified vulnerability format
â”‚
â”œâ”€â”€ LLM/                            # LLM policy generation module
â”‚   â”œâ”€â”€ README.md                  # LLM module documentation
â”‚   â”œâ”€â”€ Scripts/                  # LLM-related scripts
â”‚   â”‚   â”œâ”€â”€ generate_policies.py  # Generates policies using OpenAI/HF APIs
â”‚   â”‚   â”œâ”€â”€ evaluate_text_metrics.py  # Computes BLEU and ROUGE-L metrics
â”‚   â”‚   â”œâ”€â”€ evaluate_structure.py      # Validates policy structure compliance
â”‚   â”‚   â”œâ”€â”€ make_comparison_md.py      # Creates comparison report
â”‚   â”‚   â”œâ”€â”€ mappings.py                # CWE to ISO/NIST mappings
â”‚   â”‚   â””â”€â”€ prompt_template.txt        # LLM prompt template
â”‚   â””â”€â”€ reports/                   # Generated policy files and evaluations
â”‚       â”œâ”€â”€ policies_openai.yaml  # OpenAI-generated policies
â”‚       â”œâ”€â”€ policies_hf.yaml     # Hugging Face-generated policies
â”‚       â”œâ”€â”€ unified-vulnerabilities.json  # Unified vulnerabilities (input for LLMs)
â”‚       â”œâ”€â”€ unified-vulnerabilities.sample.json  # Sample unified report
â”‚       â”œâ”€â”€ eval_metrics.txt      # BLEU/ROUGE-L evaluation results
â”‚       â””â”€â”€ eval_structure.txt    # Structure validation results
â”‚
â”œâ”€â”€ static/                         # Static web assets
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css             # Application stylesheet
â”‚   â”œâ”€â”€ images/                    # Product images
â”‚   â”‚   â”œâ”€â”€ chair.jpg
â”‚   â”‚   â”œâ”€â”€ coffee.jpg
â”‚   â”‚   â”œâ”€â”€ hero-image.png
â”‚   â”‚   â”œâ”€â”€ lamp.jpg
â”‚   â”‚   â”œâ”€â”€ laptop.jpg
â”‚   â”‚   â””â”€â”€ mouse.jpg
â”‚   â””â”€â”€ js/
â”‚       â”œâ”€â”€ dashboard.js           # Dashboard JavaScript
â”‚       â””â”€â”€ main.js                # Main application JavaScript
â”‚
â”œâ”€â”€ templates/                      # Flask HTML templates
â”‚   â”œâ”€â”€ admin.html                 # Admin panel template
â”‚   â”œâ”€â”€ base.html                  # Base template
â”‚   â”œâ”€â”€ cart.html                  # Shopping cart template
â”‚   â”œâ”€â”€ checkout.html              # Checkout template
â”‚   â”œâ”€â”€ dashboard.html             # User dashboard template
â”‚   â”œâ”€â”€ index.html                 # Homepage template
â”‚   â”œâ”€â”€ login.html                 # Login page template
â”‚   â”œâ”€â”€ order_success.html         # Order success template
â”‚   â”œâ”€â”€ product_detail.html        # Product detail template
â”‚   â””â”€â”€ products.html              # Products listing template
â”‚
â””â”€â”€ reports/                        # Generated security reports (created at runtime)
    â””â”€â”€ (various report files generated by security tools)
```

## ğŸ“„ File Documentation

### Root Level Files

#### `app.py`
**Purpose**: Main Flask e-commerce application with intentional security vulnerabilities for testing.

**Key Features**:
- User authentication (login/register) with weak password hashing (MD5)
- Product catalog with SQL injection vulnerabilities
- Shopping cart and checkout functionality
- Admin panel with authorization bypass
- File upload endpoint with path traversal
- Payment processing with sensitive data logging
- Multiple API endpoints with various vulnerabilities

**Vulnerabilities** (25+):
- VULN-1: Weak secret key
- VULN-2: Debug mode enabled
- VULN-3: No CSRF protection
- VULN-4: SQL Injection in login
- VULN-5: Weak password hashing (MD5)
- VULN-6: SQL Injection in search
- VULN-7: Session fixation
- VULN-8: No input validation
- VULN-9: Logging sensitive data
- VULN-10-26: Various other vulnerabilities (XSS, command injection, IDOR, etc.)

#### `requirements.txt`
**Purpose**: Python package dependencies for the entire project.

**Key Dependencies**:
- Flask 3.0.0 - Web framework
- transformers, torch - For Hugging Face LLM models
- openai - For OpenAI API integration
- nltk, rouge-score, sacrebleu - For evaluation metrics
- beautifulsoup4, lxml - For report parsing
- pandas, matplotlib - For data visualization


### GitHub Workflows (`.github/workflows/`)

#### `devsecops.yml`
**Purpose**: Unified DevSecOps pipeline that runs all security scans and generates policies in a single workflow.

**What it does**:
1. **SAST (Static Application Security Testing)**:
   - Starts SonarQube Docker container
   - Configures SonarQube project and generates authentication token
   - Runs SonarScanner analysis
   - Downloads SAST issues from SonarQube API
   - Generates SAST summary report

2. **SCA (Software Composition Analysis)**:
   - Runs Snyk Python scan (if token available)
   - Runs Snyk Code scan
   - Runs OWASP Dependency-Check
   - Runs pip-audit
   - Runs Safety check
   - Runs Trivy filesystem scan
   - Generates SCA summary report
   - Uploads SARIF to GitHub Code Scanning

3. **DAST (Dynamic Application Security Testing)**:
   - Starts Flask application
   - Runs OWASP ZAP baseline scan
   - Runs OWASP ZAP full scan
   - Parses scan results
   - Generates DAST summary report

4. **Report Unification and Policy Generation**:
   - Generates summaries for SAST, SCA, and DAST
   - Normalizes report filenames
   - Unifies all reports into `unified-vulnerabilities.json`
   - Validates unified report
   - Generates policies with LLMs (OpenAI, Hugging Face)
   - Evaluates policies (BLEU, ROUGE-L metrics)
   - Creates comparison reports
   - Uploads all reports and policies as artifact

**Triggers**: 
- Push/PR to main/develop branches
- Manual trigger (`workflow_dispatch`)

**Benefits of Unified Approach**:
- **Simplicity**: Single workflow file, easier to understand and maintain
- **No artifact downloads**: All reports available directly in the same workflow
- **Complete visibility**: All scans and results visible in one workflow run
- **Sequential execution**: Ensures proper order of operations (SAST â†’ SCA â†’ DAST â†’ Unify â†’ LLM)

**Note**: Only SonarQube is used for SAST analysis. The SAST parser and summary generator can handle Bandit if its reports are added later, but the workflow currently only runs SonarQube.

---

### Parsers (`parsers/`)

#### `__init__.py`
**Purpose**: Python package initialization file to make parsers a proper Python module.

#### `base_parser.py`
**Purpose**: Base parser class providing common normalization utilities for all parsers.

**Key Methods**:
- `normalize(item: dict) -> dict`: Normalizes vulnerability items to unified schema
- `_normalize_severity(severity: str) -> str`: Maps various severity formats to CRITICAL/HIGH/MEDIUM/LOW

**Usage**: All specific parsers (SAST, SCA, DAST) inherit from this class.

#### `sast_parser.py`
**Purpose**: Parses SAST (Static Application Security Testing) reports.

**Supports**:
- **SonarQube**: Primary SAST tool used in this project (JSON format from SonarQube API)
- **Bandit**: Python security linter reports (JSON format) - optional, not used in workflow

**Output**: List of normalized vulnerability dictionaries with fields:
- vulnerability, severity, cwe, file, line, description, tool

**Inherits from**: `BaseParser`

**Note**: The workflow currently only uses SonarQube for SAST. The parser supports Bandit format for backwards compatibility or future expansion.

#### `sca_parser.py`
**Purpose**: Parses SCA (Software Composition Analysis) reports.

**Supports**:
- **OWASP Dependency-Check**: JSON and XML formats
- **SCA Summary**: Unified summary format from `generate_sca_summary.py`

**Output**: List of normalized dependency vulnerability dictionaries with fields:
- vulnerability, severity, cwe, file, description, remediation, cve, package, version, tool

**Inherits from**: `BaseParser`

#### `dast_parser.py`
**Purpose**: Parses DAST (Dynamic Application Security Testing) reports.

**Supports**:
- **OWASP ZAP**: JSON format (both "site" array and direct "alerts" formats)

**Output**: List of normalized vulnerability dictionaries with fields:
- vulnerability, severity, cwe, file, description, remediation, url, endpoint, tool

**Inherits from**: `BaseParser`

---

### Scripts (`scripts/`)

#### `parse_reports.py`
**Purpose**: Main script that unifies all security reports into a single JSON file.

**What it does**:
1. Parses SAST reports:
   - Prefers `sast-summary.json` (from `generate_sast_summary.py`)
   - Falls back to individual reports (`sonarqube-issues.json`, `bandit.json`)
   - Uses `SASTParser` for individual reports
2. Parses SCA summary report using `SCAParser`
3. Parses DAST report using `DASTParser`
4. Combines all findings into `reports/unified-vulnerabilities.json`
5. Copies unified report to `LLM/reports/unified-vulnerabilities.json` for LLM processing

**Note**: In the current setup, SAST only uses SonarQube, but the parser can handle Bandit if its reports exist.

**Usage**:
```bash
python scripts/parse_reports.py
```

**Output**: 
- `reports/unified-vulnerabilities.json`
- `LLM/reports/unified-vulnerabilities.json`

#### `validate_unified_report.py`
**Purpose**: Validates the unified vulnerability report against the schema.

**What it does**:
- Checks that report is a JSON array
- Validates each item has required fields (severity, description, tool)
- Validates severity values (CRITICAL, HIGH, MEDIUM, LOW)
- Ensures each item has either "vulnerability" or "type" field

**Usage**:
```bash
python scripts/validate_unified_report.py
```

**Exit codes**:
- 0: Validation passed
- 1: Validation failed (prints errors)
- 2: File not found or invalid JSON

#### `generate_sca_summary.py`
**Purpose**: Combines multiple SCA tool reports into a unified summary.

**What it does**:
1. Loads reports from:
   - Snyk Python (`snyk-python-report.json`)
   - Snyk Code (`snyk-code-report.json`)
   - OWASP Dependency-Check (`dependency-check-report.json`)
   - pip-audit (`pip-audit-report.json`)
   - Safety (`safety-detailed-report.json`)
   - Trivy (`trivy.sarif`)
2. Normalizes all vulnerabilities to common format
3. Generates summary statistics
4. Writes `reports/sca-summary.json` and `reports/sca-summary.txt`

**Usage**:
```bash
python scripts/generate_sca_summary.py
```

**Output**:
- `reports/sca-summary.json` (structured JSON)
- `reports/sca-summary.txt` (human-readable text)

#### `generate_sast_summary.py`
**Purpose**: Combines multiple SAST tool reports into a unified summary.

**What it does**:
1. Loads reports from:
   - SonarQube (`sonarqube-issues.json`) - primary tool used
   - Bandit (`bandit.json`) - optional, not used in current workflow
2. Normalizes all vulnerabilities to common format
3. Generates summary statistics
4. Writes `reports/sast-summary.json` and `reports/sast-summary.txt`

**Usage**:
```bash
python scripts/generate_sast_summary.py
```

**Output**:
- `reports/sast-summary.json` (structured JSON)
- `reports/sast-summary.txt` (human-readable text)

**Note**: Currently only SonarQube is used, but the script can process Bandit reports if they exist.

---

### Schemas (`schemas/`)

#### `unified_vulnerabilities.schema.json`
**Purpose**: JSON Schema definition for the unified vulnerability format.

**Required Fields**:
- `severity`: One of CRITICAL, HIGH, MEDIUM, LOW
- `description`: String description
- `tool`: Tool that found the vulnerability
- Either `vulnerability` or `type`: Vulnerability name

**Optional Fields**:
- `cwe`: CWE identifier
- `file`: File path
- `line`: Line number
- `remediation`: Remediation guidance
- `cve`: CVE identifier
- `url`: URL/endpoint
- `package`, `version`: For dependency vulnerabilities

**Usage**: Referenced by validation script and LLM generation scripts.

---

### LLM Module (`LLM/`)

#### `LLM/README.md`
**Purpose**: Documentation for the LLM policy generation module.

**Contains**: Instructions for using LLM scripts, API key setup, troubleshooting.

#### `LLM/Scripts/generate_policies.py`
**Purpose**: Generates security policies using LLM APIs (OpenAI and Hugging Face).

**What it does**:
1. Loads unified vulnerabilities from `LLM/reports/unified-vulnerabilities.json`
2. Groups vulnerabilities by theme (SQL Injection, XSS, etc.)
3. Builds prompt from template and grouped findings
4. Calls OpenAI API to generate policies
5. Calls Hugging Face API to generate policies
6. Saves outputs as YAML files

**Environment Variables Required**:
- `OPENAI_API_KEY`: OpenAI API key
- `HUGGINGFACEHUB_API_TOKEN` or `HF_TOKEN`: Hugging Face API token

**Output**:
- `LLM/reports/policies_openai.yaml`
- `LLM/reports/policies_hf.yaml`

**Usage**:
```bash
python LLM/Scripts/generate_policies.py
```

#### `LLM/Scripts/evaluate_text_metrics.py`
**Purpose**: Computes BLEU and ROUGE-L metrics to evaluate policy quality.

**What it does**:
1. Loads OpenAI policies (reference) and Hugging Face policies (candidate)
2. Computes BLEU score (n-gram precision)
3. Computes ROUGE-L score (longest common subsequence)
4. Validates schema compliance
5. Writes evaluation results to `LLM/reports/eval_metrics.txt`

**Metrics Explained**:
- **BLEU**: Measures precision of generated text compared to reference
- **ROUGE-L**: Measures recall and fluency based on longest common subsequence

**Output**: `LLM/reports/eval_metrics.txt`

#### `LLM/Scripts/evaluate_structure.py`
**Purpose**: Validates structural compliance of generated policies.

**What it does**:
1. Loads both policy YAML files
2. Validates required fields:
   - policy_id, title, mapping (iso27001, nist_csf), scope, controls, verification, owner, status
3. Computes statistics (average controls per policy, ISO/NIST mappings, etc.)
4. Writes structure evaluation to `LLM/reports/eval_structure.txt`

**Output**: `LLM/reports/eval_structure.txt`

#### `LLM/Scripts/make_comparison_md.py`
**Purpose**: Generates a comparison report between OpenAI and Hugging Face policies.

**What it does**:
1. Reads evaluation metrics and structure reports
2. Combines them into a markdown comparison report
3. Writes to `reports/llm_comparison.md`

**Output**: `reports/llm_comparison.md`

#### `LLM/Scripts/mappings.py`
**Purpose**: Defines mappings between CWE vulnerabilities and compliance frameworks.

**Key Mappings**:
- `CWE_THEME`: Maps CWE IDs to vulnerability themes (e.g., CWE-79 â†’ XSS)
- `THEME_MAPPINGS`: Maps themes to ISO 27001 and NIST CSF controls
- `THEME_CONTROLS`: Suggested controls for each theme (seed for LLM prompts)

**Usage**: Used by `generate_policies.py` to group vulnerabilities and provide context.

#### `LLM/Scripts/prompt_template.txt`
**Purpose**: Template for LLM prompts that generate security policies.

**Structure**:
- System role: "You are a cybersecurity compliance assistant"
- User role: Instructions to produce YAML policies from grouped findings
- Rules: Required fields and structure for policies
- Placeholder: `{{GROUPED_JSON}}` - replaced with actual grouped vulnerabilities

**Usage**: Loaded and populated by `generate_policies.py`.

---

### Static Assets (`static/`)

#### `static/css/style.css`
**Purpose**: Stylesheet for the Flask e-commerce application.

#### `static/js/main.js`
**Purpose**: Main JavaScript for frontend functionality (cart, forms, etc.).

#### `static/js/dashboard.js`
**Purpose**: JavaScript for user dashboard functionality.

#### `static/images/*.jpg`, `static/images/*.png`
**Purpose**: Product images and hero image for the e-commerce site.

---

### Templates (`templates/`)

#### `templates/base.html`
**Purpose**: Base HTML template with common layout (navbar, footer).

#### `templates/index.html`
**Purpose**: Homepage template displaying featured products.

#### `templates/products.html`
**Purpose**: Products listing page with search and category filters.

#### `templates/product_detail.html`
**Purpose**: Individual product detail page.

#### `templates/cart.html`
**Purpose**: Shopping cart page.

#### `templates/checkout.html`
**Purpose**: Checkout page.

#### `templates/login.html`
**Purpose**: User login page.

#### `templates/register.html`
**Purpose**: User registration page.

#### `templates/dashboard.html`
**Purpose**: User dashboard showing orders and account info.

#### `templates/admin.html`
**Purpose**: Admin panel template (requires admin role).

#### `templates/order_success.html`
**Purpose**: Order confirmation page.

---

## ğŸš€ Getting Started

### Prerequisites

- Python 3.11+
- Git
- Docker (for DAST scans)
- GitHub account (for CI/CD)

### Installation

1. **Clone the repository**:
```bash
git clone <your-repo-url>
cd AI-DevSecOps-Project-2
```

2. **Install Python dependencies**:
```bash
pip install -r requirements.txt
# Optional: Install security tools for local testing
# pip install bandit pip-audit safety
```

3. **Set up environment variables** (create `.env` file):
```bash
OPENAI_API_KEY=your_openai_key
HUGGINGFACEHUB_API_TOKEN=your_hf_token
SNYK_TOKEN=your_snyk_token  # Optional
```

4. **Create required directories**:
```bash
mkdir -p reports LLM/reports
```

5. **Initialize the database**:
```bash
python app.py  # Creates ecommerce.db with sample data
```

### Running Locally

1. **Start the Flask application**:
```bash
python app.py
```
Application will be available at `http://localhost:5000`

2. **Run security scans manually**:
```bash
# SAST (SonarQube - requires Docker and setup)
# Note: SonarQube requires Docker setup. See devsecops.yml workflow for setup details.
# For local testing, you can also use Bandit:
# bandit -r . -f json -o reports/bandit.json

# SCA
pip-audit -f json -o reports/pip-audit-report.json
safety check --full-report --json > reports/safety-detailed-report.json
python scripts/generate_sca_summary.py

# DAST (requires app running)
docker run --rm --network="host" \
  ghcr.io/zaproxy/zaproxy:stable \
  zap-baseline.py -t http://localhost:5000 \
  -J reports/dast-report.json

# Generate SAST summary (if you have SonarQube report)
python scripts/generate_sast_summary.py
```

3. **Generate summaries**:
```bash
# Generate SAST summary (requires SonarQube report or other SAST reports)
python scripts/generate_sast_summary.py

# Generate SCA summary
python scripts/generate_sca_summary.py
```

4. **Unify reports**:
```bash
python scripts/parse_reports.py
```

5. **Generate policies**:
```bash
python LLM/Scripts/generate_policies.py
```

6. **Evaluate policies**:
```bash
python LLM/Scripts/evaluate_text_metrics.py
python LLM/Scripts/evaluate_structure.py
python LLM/Scripts/make_comparison_md.py
```

---

## ğŸ”„ DevSecOps Pipeline

### Pipeline Flow

```
Code Push/PR / Manual Trigger
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DevSecOps Pipeline (devsecops.yml)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. SAST Analysis                                â”‚
â”‚     - SonarQube Docker container                â”‚
â”‚     - SonarScanner analysis                     â”‚
â”‚     - Downloads SAST issues                     â”‚
â”‚     - Generates SAST summary                    â”‚
â”‚                                                  â”‚
â”‚  2. SCA Analysis                                â”‚
â”‚     - Snyk Python & Code scans                 â”‚
â”‚     - OWASP Dependency-Check                    â”‚
â”‚     - pip-audit, Safety                         â”‚
â”‚     - Trivy filesystem scan                     â”‚
â”‚     - Generates SCA summary                     â”‚
â”‚                                                  â”‚
â”‚  3. DAST Analysis                                â”‚
â”‚     - Start Flask application                   â”‚
â”‚     - OWASP ZAP Baseline scan                  â”‚
â”‚     - OWASP ZAP Full scan                       â”‚
â”‚     - Generates DAST summary                    â”‚
â”‚                                                  â”‚
â”‚  4. Report Unification                          â”‚
â”‚     - Generate all summaries                    â”‚
â”‚     - Normalize report filenames               â”‚
â”‚     - Parse all reports                         â”‚
â”‚     - Unify to single format                    â”‚
â”‚     - Validate schema                           â”‚
â”‚     - Create unified-vulnerabilities.json       â”‚
â”‚                                                  â”‚
â”‚  5. LLM Policy Generation                       â”‚
â”‚     - OpenAI GPT-4o-mini                        â”‚
â”‚     - Hugging Face models                       â”‚
â”‚     - Generates policies_openai.yaml            â”‚
â”‚     - Generates policies_hf.yaml                â”‚
â”‚                                                  â”‚
â”‚  6. Evaluation                                  â”‚
â”‚     - BLEU metrics                              â”‚
â”‚     - ROUGE-L metrics                           â”‚
â”‚     - Structure validation                      â”‚
â”‚     - Generates comparison report              â”‚
â”‚                                                  â”‚
â”‚  7. Artifact Upload                             â”‚
â”‚     - All unified reports                       â”‚
â”‚     - Generated policies                        â”‚
â”‚     - Evaluation results                        â”‚
â”‚     - Summary reports                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CI/CD Workflow

The project uses a **unified DevSecOps pipeline** that runs all security scans and policy generation in a single workflow:

**`devsecops.yml`**: Complete DevSecOps pipeline
- **SAST**: SonarQube analysis with Docker container
- **SCA**: Multiple tools (Snyk, Dependency-Check, pip-audit, Safety, Trivy)
- **DAST**: OWASP ZAP baseline and full scans
- **Unification**: All reports combined into `unified-vulnerabilities.json`
- **Policy Generation**: LLM-based policy generation (OpenAI, Hugging Face)
- **Evaluation**: BLEU, ROUGE-L, and structural validation
- **Artifacts**: All reports, summaries, and policies uploaded as single artifact

**Architecture Benefits**: 
- **Simplicity**: Single workflow file, easier to understand and maintain
- **No artifact downloads**: All reports available directly in the same workflow
- **Complete visibility**: All scans and results visible in one workflow run
- **Sequential execution**: Ensures proper order of operations (SAST â†’ SCA â†’ DAST â†’ Unify â†’ LLM)

---

## âš™ï¸ Configuration

### GitHub Secrets

Set these secrets in your GitHub repository settings:

- `OPENAI_API_KEY`: OpenAI API key for policy generation
- `HUGGINGFACEHUB_API_TOKEN`: Hugging Face API token
- `SNYK_TOKEN`: Snyk token for dependency scanning (optional)

### Local Configuration

Create a `.env` file in the project root:
```
OPENAI_API_KEY=your_key_here
HUGGINGFACEHUB_API_TOKEN=your_token_here
HF_MODEL=microsoft/Phi-3-mini-4k-instruct  # Optional: specify HF model
```

---

## ğŸ“Š Evaluation Metrics

### BLEU (Bilingual Evaluation Understudy)

Measures precision of generated text:
- Range: 0-100 (higher is better)
- Compares n-grams between generated and reference policies

### ROUGE-L (Recall-Oriented Understudy for Gisting - Longest)

Measures recall and fluency:
- Range: 0-1 (higher is better)
- Based on longest common subsequence
- Considers both directions (referenceâ†’candidate and candidateâ†’reference)

### Structure Validation

Checks for:
- Required fields (policy_id, title, mapping, scope, controls, etc.)
- ISO 27001 control mappings
- NIST CSF control mappings
- Policy completeness

---

## ğŸ” Troubleshooting

### DAST Workflow Fails

- Ensure Flask app starts successfully
- Check Docker is available in GitHub Actions
- Verify app is accessible on `http://localhost:5000`

### LLM Generation Fails

- Verify API keys are set correctly
- Check API quotas and rate limits
- Ensure `unified-vulnerabilities.json` exists

### Parsing Errors

- Verify report files exist in `reports/` directory
- Check report formats match expected structure
- Run validation script to identify issues

---

## ğŸ“ Notes

- **Intentional Vulnerabilities**: The Flask app contains vulnerabilities for testing purposes. **DO NOT** deploy this application to production!

- **Workflow Architecture**: The project uses a unified `devsecops.yml` workflow that runs all security scans (SAST, SCA, DAST) sequentially and then generates policies using LLMs. See the [DevSecOps Pipeline](#-devsecops-pipeline) section for details.

- **API Costs**: LLM generation uses external APIs which may incur costs. Monitor usage.

---

## ğŸ“š References

- [NIST Cybersecurity Framework](https://www.nist.gov/cyberframework)
- [ISO/IEC 27001](https://www.iso.org/standard/54534.html)
- [OWASP Top 10](https://owasp.org/www-project-top-ten/)
- [OWASP ZAP](https://www.zaproxy.org/)
- [SonarQube](https://www.sonarqube.org/) - Primary SAST tool used in this project
- [Bandit](https://bandit.readthedocs.io/) - Optional SAST tool (parser supports it for local testing)

---

## ğŸ“„ License

This project is for educational purposes. See LICENSE file for details.

---

**Last Updated**: 2025
**Project Version**: 1.0
